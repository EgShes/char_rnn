{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level language model\n",
    "\n",
    "In the previous tasks you have written character-level language model. Time has come to grow up.\n",
    "\n",
    "Word language models face a lot of new problems for you to solve. There are some of them:\n",
    "  * How to read long texts (Gbs of data)\n",
    "  * How to build vocabulry (and to effectively reduce its size)\n",
    "  * How to deal with out-of-vocabulary (OOV) words\n",
    "  * How to construct batch of _uncorrelated_ examples (not from the same text)\n",
    "  * How and when to drop RNN state\n",
    "  * What special tokens should be used? BOS? EOS?\n",
    "\n",
    "**Results of this task:**\n",
    "  * Text preprocessing\n",
    "  * Batcher\n",
    "  * Trained language model:\n",
    "    * model should use truncated backpropagation through time\n",
    "    * model should drop RNN state between different documents (eg. wikipedia articles)\n",
    "  * Test set perplexity\n",
    "\n",
    "**Additional points:**\n",
    "  * Text preprocessing and batching that works with large files (does not load all the file to memory)\n",
    "  * AWD-LSTM or other uncommon RNN architectures (SRU, QRNN)\n",
    "  * Use popular dataset \n",
    "\n",
    "It is becoming common to use [byte-pair encoding](https://github.com/google/sentencepiece) to solve vocabulary problem. Use it! Here is an [example](https://github.com/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn import Module, Embedding, GRU, Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is news in russian language. Data was taken from https://github.com/maxoodf/russian_news_corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('russian_news_orig.txt', 'r'):\n",
    "    corpus = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N articles: 1449368\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('N articles:', len(corpus))\n",
    "\n",
    "plt.hist([len(i.split(' ')) for i in corpus], range(0, 1000))\n",
    "plt.xlabel('N words in article')\n",
    "plt.ylabel('N articles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_corpus = corpus[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(corpus, min_sent_len=3):\n",
    "    \"\"\"\n",
    "    input: list of articles\n",
    "    output: list of sentences\n",
    "    \"\"\"\n",
    "    proc_corpus = []\n",
    "    with tqdm(total=len(corpus)) as pbar:\n",
    "        for text in corpus:\n",
    "            sentences = text.split('.')\n",
    "            proc_sentences = [['<bos>'] + re.sub(r'[^\\w\\s]', '', sent).split(' ') + ['<eos>'] \n",
    "                              for sent in sentences]\n",
    "            proc_corpus += [sent for sent in proc_sentences if len(sent) > min_sent_len]\n",
    "            pbar.update(1)\n",
    "        \n",
    "    return proc_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 9688.58it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = process_corpus(short_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N sentences: 59752\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGi9JREFUeJzt3X+QZWV95/H3R0QTEQWEsDgQhyQTLdQ4kC7E1bhKgoxkS2JiEoylGFnHysJGje4Gki0xGiyIGqNRKcdAgPwQWYU4RYhkRLKoUWAGEZlBZMKPMBOEURCMrpjB7/5xnoZr0zN9z0zfvrdn3q+qW33Oc359u+/t/vbz4zwnVYUkScN6zLgDkCQtLiYOSVIvJg5JUi8mDklSLyYOSVIvJg5JUi8mDklSLyYOSVIvJg5JUi+PHXcAo7D//vvX0qVLxx2GJC0q69at+2ZVHTDXfrtk4li6dClr164ddxiStKgkuWOY/WyqkiT1YuKQJPVi4pAk9WLikCT1YuKQJPVi4pAk9WLikCT1YuKQJPVi4pAk9bJL3jmuztJT//5H1m8/85fHFImkXYk1DklSLyYOSVIvJg5JUi8mDklSLyYOSVIvJg5JUi8mDklSL97HsRsZvK/Dezok7aiR1TiS/FiSa5J8Jcn6JH/Uyg9NcnWSjUk+nuRxrfzxbX1j27504FyntfKbkxw7qpglSXMbZVPVg8DRVfUcYDmwIslRwFnA+6rqZ4D7gJPa/icB97Xy97X9SHIYcALwTGAF8OEke4wwbknSdoysqaqqCvj3trpnexVwNPBbrfx84O3A2cDxbRngE8AHk6SVX1hVDwK3JdkIHAl8cVSxL1YzpxiRpFEYaed4kj2SXA/cA6wB/gX4dlVtbbtsApa05SXAnQBt+/3AUwbLZzlm8Fork6xNsnbLli2j+HYkSYy4c7yqHgKWJ9kHuAR4xgivtQpYBTA1NVWjus6uwgkQJe2oBRmOW1XfBq4Engfsk2Q6YR0MbG7Lm4FDANr2JwPfGiyf5RhJ0gIb5aiqA1pNgyQ/DhwD3ESXQF7RdjsR+FRbXt3Wads/2/pJVgMntFFXhwLLgGtGFbckaftG2VR1EHB+GwH1GOCiqro0yQbgwiR/DHwZOKftfw7wV63z+166kVRU1fokFwEbgK3Aya0JTJI0BqMcVXUDcPgs5bfSjYqaWf594Ne3ca4zgDPmO0ZJUn9OOSJJ6sXEIUnqxcQhSerFxCFJ6sXZcQV4Q6Ck4VnjkCT1YuKQJPVi4pAk9WIfxyLmNOqSxsEahySpFxOHJKkXE4ckqRcThySpFxOHJKkXE4ckqRcThySpFxOHJKkXE4ckqRcThySpF6cc0aycZl3StljjkCT1YuKQJPViU5WGYtOVpGkjq3EkOSTJlUk2JFmf5I2t/O1JNie5vr2OGzjmtCQbk9yc5NiB8hWtbGOSU0cVsyRpbqOscWwF3lJV1yXZG1iXZE3b9r6qes/gzkkOA04Angk8FfhMkp9tmz8EHANsAq5NsrqqNowwdknSNowscVTVXcBdbfk7SW4ClmznkOOBC6vqQeC2JBuBI9u2jVV1K0CSC9u+Jg5JGoMF6eNIshQ4HLgaeD5wSpLXAGvpaiX30SWVLw0ctolHEs2dM8qfO+KQJ5JP/JM0CUY+qirJE4FPAm+qqgeAs4GfBpbT1UjeO0/XWZlkbZK1W7ZsmY9TSpJmMdIaR5I96ZLG31TVxQBVdffA9o8Cl7bVzcAhA4cf3MrYTvnDqmoVsApgamqq5ulbGCtrGJIm0ShHVQU4B7ipqv50oPyggd1eDtzYllcDJyR5fJJDgWXANcC1wLIkhyZ5HF0H+upRxS1J2r5R1jieD7wa+GqS61vZHwCvTLIcKOB24A0AVbU+yUV0nd5bgZOr6iGAJKcAlwN7AOdW1foRxi1J2o5Rjqr6PJBZNl22nWPOAM6Ypfyy7R0nSVo4TjkiSerFKUe0Q5yCRNp9WeOQJPVi4pAk9WLikCT1YuKQJPVi4pAk9WLikCT1YuKQJPVi4pAk9WLikCT1YuKQJPVi4pAk9WLikCT14iSHmhdOeijtPqxxSJJ6MXFIknoxcUiSeumVOJI8JsmTRhWMJGnyzZk4kvxtkicl2Qu4EdiQ5H+OPjRJ0iQaZlTVYVX1QJJXAf8AnAqsA9490si0qA2OsnKElbRrGaapas8kewK/Aqyuqv8AarRhSZIm1TCJ4yPA7cBewFVJngY8MMqgJEmTa86mqqr6APCBgaI7krx4dCFJkibZMJ3jByY5J8k/tPXDgBOHOO6QJFcm2ZBkfZI3tvL9kqxJckv7um8rT5IPJNmY5IYkRwyc68S2/y1J5ry2JGl0hmmqOg+4HHhqW/868KYhjtsKvKWqDgOOAk5uSedU4IqqWgZc0dYBXgosa6+VwNnQJRrgdOC5wJHA6dPJRpK08IZJHPtX1UXADwGqaivw0FwHVdVdVXVdW/4OcBOwBDgeOL/tdj5dpzut/ILqfAnYJ8lBwLHAmqq6t6ruA9YAK4b9BiVJ82uYxPHdJE+hjaRKchRwf5+LJFkKHA5cDRxYVXe1Td8ADmzLS4A7Bw7b1Mq2VT7zGiuTrE2ydsuWLX3CkyT1MMx9HL8HrAZ+OskXgAOAVwx7gSRPBD4JvKndD/LwtqqqJPMytLeqVgGrAKamphwuLEkjMsyoquuS/Bfg6UCAm9u9HHNq9398Evibqrq4Fd+d5KCquqs1Rd3TyjcDhwwcfnAr2wy8aEb5Pw1zfUnS/JszcSQ5me4P//q2vm+SV1bVh+c4LsA5wE1V9acDm1bTjco6s3391ED5KUkupOsIv78ll8uBdw10iL8EOG3o73ARmflMC0maRMP0cby+qr49vdI6qF8/xHHPB14NHJ3k+vY6ji5hHJPkFuCX2jrAZcCtwEbgo8B/b9e7F3gncG17vaOVSZLGYJg+jj2SpKqmO8f3AB4310FV9Xm6pq3Z/OIs+xdw8jbOdS5w7hCxSpJGbJjE8Wng40k+0tbf0MokSbuhYRLH79Mli99p62uAvxhZRJKkiTbMqKof0t3Fffbow5EkTbphRlU9H3g78LS2f+i6JH5qtKFJkibRME1V5wBvpnt405xTjUgzzRxm7IOdpMVtmMRxf1X9w8gjkSQtCsMkjiuTvBu4GHhwunB6AkNJ0u5lmMTx3PZ1aqCsgKPnP5zFz2YZSbu6YUZV+bQ/SdLDdugJgElOGn1okqRJNMonAEqSdkEjewKgJGnXtCBPAJQk7Tp29AmAvz7SqLRLc+SZtLgNkzjWAz/yBECGq6lIknZBwySAL1bV1qpaX1U3tsfGfnHUgUmSJtM2axxJ/hOwBPjxJIfzyEOZngQ8YQFikyRNoO01VR0LvBY4GBh8Zvh3gD8YYUySpAm2zcRRVecD5yf5tar65ALGJEmaYMN0jl+a5LeApYP7V9U7RhWUJGlyDZM4PkV338Y6BmbHlSTtnoZJHAdX1YqRRyJJWhSGGY77z0mePfJIJEmLwjCJ4wXAuiQ3J7khyVeT3DDXQUnOTXJPkhsHyt6eZHOS69vruIFtpyXZ2K5z7ED5ila2Mcmpfb9BSdL8Gqap6qU7eO7zgA8CF8wof19VvWewIMlhwAnAM+lm4f1Mkp9tmz8EHANsAq5NsrqqNuxgTJpATkEiLS5z1jiq6g7gEODotvy9IY+7Crh3yDiOBy6sqger6jZgI3Bke22sqlur6gfAhW1fSdKYDPMgp9OB3wdOa0V7An+9E9c8pTV5nZtk31a2BLhzYJ9NrWxb5ZKkMRmmj+PlwMuA7wJU1b8Be+/g9c4GfhpYDtwFvHcHz/MoSVYmWZtk7ZYtW+brtJKkGYZJHD+oquKR53HstaMXq6q7q+qhqvoh8FG6piiAzXTNYdMObmXbKp/t3Kuqaqqqpg444IAdDVGSNIdhEsdFST4C7JPk9cBn6P7o95bkoIHVlwPTI65WAyckeXySQ4FlwDXAtcCyJIcmeRxdB/rqHbm2JGl+zDmqqqrek+QY4AG6Z3K8rarWzHVcko8BLwL2T7IJOB14UZLldLWX24E3tGusT3IRsAHYCpxcVQ+185xC98zzPYBzq2p9329SkjR/5kwcrWnqs1W1JsnTgacn2bM9l2ObquqVsxSfs539zwDOmKX8MuCyueKUJC2MYZqqrgIen2QJ8Gng1XT3aEiSdkPD3ACYqvpekpOAs6vqT5JcP+rAtPvyhkBpsg1T40iS5wGvAqZ/o/cYXUiSpEk2TI3jjXQ3/13SOrF/CrhytGHtPmb+dy1Jk26YUVVX0fVzTK/fCvzuKIOSJE2uYWoc0ljZ5yFNlmH6OCRJepiJQ5LUyzabqpK8bTvHVVW9cwTxSJIm3Pb6OL47S9kTgP8GPAUwcUjSbmibiaOqHp7yPMnedMNyX0f3MKV5mw5dkrS4bHdUVZL9gN+ju/nvfOCIqrpvIQKTJE2m7fVxvBv4VWAV8Oyq+vcFi0qSNLG2V+N4C/Ag8L+BP0wyXR66zvEnjTi2XZJ3ikta7LbXx+FQXUnSo5gcJEm9OOWIFh2nIJHGyxqHJKkXE4ckqRcThySpFxOHJKkXE4ckqRcThySpl5EljiTnJrknyY0DZfslWZPklvZ131aeJB9IsjHJDUmOGDjmxLb/LUlOHFW8kqThjLLGcR6wYkbZqcAVVbUMuKKtA7wUWNZeK4Gz4eFJFk8HngscCZw+nWwkSeMxssRRVVcB984oPp5ull3a118ZKL+gOl8C9klyEHAssKaq7m2z8q7h0clIkrSAFvrO8QOr6q62/A3gwLa8BLhzYL9NrWxb5dLDBu8k9y5yafTG1jleVQXUfJ0vycoka5Os3bJly3ydVpI0w0InjrtbExTt6z2tfDNwyMB+B7eybZU/SlWtqqqpqpo64IAD5j1wSVJnoZuqVgMnAme2r58aKD8lyYV0HeH3V9VdSS4H3jXQIf4S4LQFjnmn+PwNSbuakSWOJB8DXgTsn2QT3eioM4GLkpwE3AH8Rtv9MuA4YCPwPeC3Aarq3iTvBK5t+72jqmZ2uEuSFlC6roZdy9TUVK1du3Ys17aGMVnsLJeGl2RdVU3NtZ93jkuSejFxSJJ6MXFIknoxcUiSejFxSJJ6MXFIknoxcUiSejFxSJJ6WegpR6QFNfOGTG8IlHaeNQ5JUi8mDklSLyYOSVIvJg5JUi92jmu3Yme5tPOscUiSejFxSJJ6MXFIknoxcUiSejFxSJJ6MXFIknoxcUiSevE+Du3WvK9D6s8ahySpFxOHJKmXsTRVJbkd+A7wELC1qqaS7Ad8HFgK3A78RlXdlyTA+4HjgO8Br62q68YRt3Z9Nl1JcxtnjePFVbW8qqba+qnAFVW1DLiirQO8FFjWXiuBsxc8UknSwyapqep44Py2fD7wKwPlF1TnS8A+SQ4aR4CSpPEljgL+Mcm6JCtb2YFVdVdb/gZwYFteAtw5cOymVvYjkqxMsjbJ2i1btowqbkna7Y1rOO4Lqmpzkp8A1iT52uDGqqok1eeEVbUKWAUwNTXV61hJ0vDGkjiqanP7ek+SS4AjgbuTHFRVd7WmqHva7puBQwYOP7iVSSNnZ7n0aAveVJVkryR7Ty8DLwFuBFYDJ7bdTgQ+1ZZXA69J5yjg/oEmLUnSAhtHjeNA4JJulC2PBf62qj6d5FrgoiQnAXcAv9H2v4xuKO5GuuG4v73wIUuSpi144qiqW4HnzFL+LeAXZykv4OQFCE2a02DTlc1W2l1N0nBcSdIiYOKQJPVi4pAk9eK06tIOcqiudlfWOCRJvVjjkOaJNRDtLqxxSJJ6MXFIknqxqUoaEZuutKuyxiFJ6sXEIUnqxaYqaYHYdKVdhTUOSVIv1jikMbEGosXKxCFNCKds12JhU5UkqRcThySpF5uqpAlk/4cmmYlDWgRmJpKZTCxaSDZVSZJ6scYh7QJs2tJCMnFIuyGH/mpnmDikXdBcfSLb29dEorksmsSRZAXwfmAP4C+q6swxhyTtkuyI11wWReJIsgfwIeAYYBNwbZLVVbVhvJFJu58+tRnYfqKxtrM4LYrEARwJbKyqWwGSXAgcD5g4pAm3M81mM5lYJsNiSRxLgDsH1jcBzx1TLJLGpG9tZ2fMTFI7c+1RJrxx1NoWS+KYU5KVwMq2+u9Jbt6J0+0PfHPno5p3kxoXTG5skxoXTG5skxoXLGBsOavX7tuNq+e5dsos1+rzM3vaMDstlsSxGThkYP3gVvawqloFrJqPiyVZW1VT83Gu+TSpccHkxjapccHkxjapccHkxjapccFoYlssd45fCyxLcmiSxwEnAKvHHJMk7ZYWRY2jqrYmOQW4nG447rlVtX7MYUnSbmlRJA6AqroMuGyBLjcvTV4jMKlxweTGNqlxweTGNqlxweTGNqlxwQhiS1XN9zklSbuwxdLHIUmaECaOAUlWJLk5ycYkp445lnOT3JPkxoGy/ZKsSXJL+7rvGOI6JMmVSTYkWZ/kjRMU248luSbJV1psf9TKD01ydXtfP94GWCy4JHsk+XKSSycsrtuTfDXJ9UnWtrJJeD/3SfKJJF9LclOS501IXE9vP6vp1wNJ3jQhsb25ffZvTPKx9jsx758zE0czMK3JS4HDgFcmOWyMIZ0HrJhRdipwRVUtA65o6wttK/CWqjoMOAo4uf2cJiG2B4Gjq+o5wHJgRZKjgLOA91XVzwD3ASeNITaANwI3DaxPSlwAL66q5QPDNifh/Xw/8OmqegbwHLqf3djjqqqb289qOfDzwPeAS8YdW5IlwO8CU1X1LLqBRCcwis9ZVfnq+nmeB1w+sH4acNqYY1oK3DiwfjNwUFs+CLh5An5un6KbQ2yiYgOeAFxHN8PAN4HHzvY+L2A8B9P9MTkauBTIJMTVrn07sP+MsrG+n8CTgdto/bCTEtcscb4E+MIkxMYjM2zsRzfw6VLg2FF8zqxxPGK2aU2WjCmWbTmwqu5qy98ADhxnMEmWAocDVzMhsbXmoOuBe4A1wL8A366qrW2Xcb2vfwb8L+CHbf0pExIXQAH/mGRdm4EBxv9+HgpsAf6yNe/9RZK9JiCumU4APtaWxxpbVW0G3gP8K3AXcD+wjhF8zkwci1R1/z6MbUhckicCnwTeVFUPDG4bZ2xV9VB1TQgH002O+YxxxDEoyX8F7qmqdeOOZRteUFVH0DXTnpzkhYMbx/R+PhY4Aji7qg4HvsuMpp8J+B14HPAy4P/M3DaO2FqfyvF0SfepwF48url7Xpg4HjHntCYT4O4kBwG0r/eMI4gke9Iljb+pqosnKbZpVfVt4Eq6qvk+SabvWRrH+/p84GVJbgcupGuuev8ExAU8/J8qVXUPXVv9kYz//dwEbKqqq9v6J+gSybjjGvRS4Lqqurutjzu2XwJuq6otVfUfwMV0n715/5yZOB6xGKY1WQ2c2JZPpOtfWFBJApwD3FRVfzphsR2QZJ+2/ON0fS830SWQV4wrtqo6raoOrqqldJ+rz1bVq8YdF0CSvZLsPb1M12Z/I2N+P6vqG8CdSZ7ein6R7jEKY/+cDXgljzRTwfhj+1fgqCRPaL+n0z+z+f+cjbNjadJewHHA1+naxf9wzLF8jK6d8j/o/vs6ia5d/ArgFuAzwH5jiOsFdFXwG4Dr2+u4CYnt54Avt9huBN7Wyn8KuAbYSNes8Pgxvq8vAi6dlLhaDF9pr/XTn/sJeT+XA2vb+/l3wL6TEFeLbS/gW8CTB8rGHhvwR8DX2uf/r4DHj+Jz5p3jkqRebKqSJPVi4pAk9WLikCT1YuKQJPVi4pAk9WLi0KKRpJK8d2D9rUnevoDXPy/JK+beE5K8LGOYYTnJ8iTHLfR1tXsxcWgxeRD41ST7j/pCA3fa7pCqWl1VZ85XPD0sp7uvRhoZE4cWk610j8F88/Z2as+W2CedbyV5TSu/IMkx7RkFf9n2+3KSF7ftr02yOslngSva8R9M94yWzwA/MXCNM9M9k+SGJO+ZJYbXJvlgWz4vyQeS/HOSW2ertbQ7uP8+3bNEbkzym63855P83zYB4eUDU1r8U5Kz0j1/5OtJfqHNePAO4DfTPSfiN9t5z237fTnJ8QPxXZzk0+meH/EnA7GsSHJdi+WKgfgedR7tnhbNM8el5kPADYN/6GbxBbo5eu4AbgV+AbiAbt6q3wFOppuH7tlJnkE3M+zPtmOPAH6uqu5N8qvA0+mez3Ig3fQN5yZ5CvBy4BlVVdPTnMzhILq77p9BNzXFJ2ZsXwH8W1X9MkCSJ7c5wf4cOL6qtrRkcgbwunbMY6vqyNY0dXpV/VKSt9E9j+GUdp530U1x8roW5zUtCUJXOzmcriZ3c5I/B74PfBR4YVXdlmS/tu8fznaeqvruEN+7djEmDi0qVfVAkgvoHljz/7ax2+eAF9IljrOBlekecnNfVX03yQvo/iBTVV9LcgcwnTjWVNW9bfmFwMeq6iHg31pNBLrpqr8PnJPuaX6XDhH631XVD4ENSWabbvurwHuTnEU3JcnnkjwLeBawppt6iD3opqGZNj3B5Dq6Z7fM5iV0Eyy+ta3/GPCTbfmKqrofIMkG4Gl003pcVVW3AQz8LLZ1nsEHU2k3YeLQYvRndA9p+sttbL+Krlbxk3T/Kb+cbpK3zw1x7jn/g66qrUmOpJtE7hXAKXQz3m7PgwPLmeWcX09yBF3/xB+3JqJLgPVV9bw5zvkQ2/5dDvBrVXXzjxQmz50R0/bOsc3zaPdkH4cWnfZf8EVs4xGYVXUnsD+wrKpuBT4PvJUuoUCXQF4F0JqofpLu6W0zXUXXX7BH61uY7gt5It3kdpfR9bc8Z2e/pyRPBb5XVX8NvJuuyexm4IAkz2v77JnkmXOc6jvA3gPrlwP/I63KkuTwOY7/EvDCJIe2/aebqvqeR7swE4cWq/fSJYdtuZpupmPoEsUSugQC8GHgMUm+CnwceG1VPfjoU3AJ3UynG+j6SL7YyvcGLk1yQzvn7+3E9zHt2XT9BtcDpwN/XFU/oKvRnJXkK3QzEf/nOc5zJXDYdOc48E5gT7p+ofVtfZuqaguwEri4XfPjbVOv82jX5uy4kqRerHFIknoxcUiSejFxSJJ6MXFIknoxcUiSejFxSJJ6MXFIknoxcUiSevn/C4nTqJW0WE4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('N sentences:', len(sentences))\n",
    "\n",
    "plt.hist([len(i) for i in sentences], range(0, 80))\n",
    "plt.xlabel('N words in sentence')\n",
    "plt.ylabel('N sentences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<bos>',\n",
       "  'ru',\n",
       "  'мид',\n",
       "  'еще',\n",
       "  'раз',\n",
       "  'напомнил',\n",
       "  'что',\n",
       "  'россия',\n",
       "  'асада',\n",
       "  'не',\n",
       "  'поддерживает',\n",
       "  '<eos>'],\n",
       " ['<bos>',\n",
       "  '',\n",
       "  'российская',\n",
       "  'военная',\n",
       "  'операция',\n",
       "  'в',\n",
       "  'сирии',\n",
       "  'не',\n",
       "  'направлена',\n",
       "  'на',\n",
       "  'поддержку',\n",
       "  'президента',\n",
       "  'башара',\n",
       "  'асада',\n",
       "  'заявила',\n",
       "  'официальный',\n",
       "  'представитель',\n",
       "  'мид',\n",
       "  'рф',\n",
       "  'мария',\n",
       "  'захарова',\n",
       "  '<eos>']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def fit(self, sentences, max_vocab=50000):\n",
    "        c = Counter([word for sent in sentences for word in sent])\n",
    "        freq_sorted = sorted(c.items(), key=lambda item: item[1], reverse=True)\n",
    "        self._vocab = ['<pad>', '<unk>'] + [word for word, _ in freq_sorted[:max_vocab - 2]]\n",
    "        self._w2i = {w: i for i, w in enumerate(self._vocab)}\n",
    "        del c, freq_sorted\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._vocab)\n",
    "\n",
    "    def transform(self, sent, remove_empty_srtings=True):\n",
    "        proc_sent = []\n",
    "        for word in sent:\n",
    "            if remove_empty_srtings and word == '':\n",
    "                continue\n",
    "            proc_sent.append(self._w2i[word] if word in self._w2i else self._w2i['<unk>'])\n",
    "        return proc_sent\n",
    "        \n",
    "    def w2i(self, word):\n",
    "        return self._w2i[word] if word in self._w2i else self._w2i['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Vocabulary at 0x7f278bece5c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = Vocabulary()\n",
    "voc.fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sentences, max_vocab=50000, vocab=None):\n",
    "        self.sents = sentences\n",
    "        if vocab:\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab = Vocabulary()\n",
    "            self.vocab.fit(self.sents, max_vocab=max_vocab)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.vocab.transform(self.sents[index])\n",
    "        x = torch.LongTensor(item[:-1])\n",
    "        y = torch.LongTensor(item[1:])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(batch, maxlen=50):\n",
    "    lengths = [min(len(i[0]), maxlen) for i in batch]\n",
    "    \n",
    "    batch = [i[1] for i in sorted(zip(lengths, batch), key=lambda x: x[0], reverse=True)]\n",
    "    lengths = torch.LongTensor(sorted(lengths, reverse=True))\n",
    "    \n",
    "    x = pad_sequence([i[0][:maxlen] for i in batch], batch_first=True)\n",
    "    y = pad_sequence([i[1][:maxlen] for i in batch], batch_first=True)\n",
    "    return (x, y), lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check loder implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = MyDataset(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(t, 10, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 29]) tensor([29, 23, 20, 19, 15, 14, 13, 13, 11,  5])\n",
      "tensor([[    3,    30,  7478,  5917, 34629,   271,   147,  9341,     9,    41,\n",
      "          7479,   172,    17,   387,  7479,   456, 34630, 21473,   706,     6,\n",
      "          1626,     6, 10158,   299, 21474,  3956, 34631,  4834,    65],\n",
      "        [    3,   110,    87,   172,   277,    96,     9,     7,   827,   702,\n",
      "           241,     6,  5067,     5,   277,    23,   429,    75,  2658,   430,\n",
      "             7,  3460,  1446,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,   486,  8036,  3054,     5,   277,     8,  6273,     7,   890,\n",
      "           204,  5607,  2290,  1013,   936,   284,   465,    83,  1062,  1474,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3, 11143, 34632,   669,    10, 34633,     6,  8614, 15715,     5,\n",
      "            47,   160,     6,    10, 34634, 13784,   560,   152,    86,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,   220,  1626,     6,  6646,  4248,  3253,     9,  1147,    27,\n",
      "          6647,     7,   375,  2749,  1860,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,   281,    61,   327,  1124,    21, 10159,  6276, 15714,   295,\n",
      "          9342, 12327,     5,  2748,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,    11,    62,    93,  6274,    46,     8,  1684,  1762,  1041,\n",
      "            12,  1041,  2194,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,   187,   993,  6275, 11141, 11142, 18138,     1,    49,   669,\n",
      "            10,  1047,   277,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,   151,   465,    50,   101,  1240,     9,   128,  2290,     8,\n",
      "          2098,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,     1,  9343,   363,    61,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "for (x, y), lengths in loader:\n",
    "    print(x.shape, lengths)\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data and make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len 41826\n",
      "val len 5975\n",
      "test len 11951\n"
     ]
    }
   ],
   "source": [
    "l = len(sentences)\n",
    "shuffled_indxs = np.random.permutation(l)\n",
    "train_idxs = shuffled_indxs[:int(l * 0.7)]\n",
    "val_idxs = shuffled_indxs[int(l * 0.7):int(l * 0.8)]\n",
    "test_idxs = shuffled_indxs[int(l * 0.8):]\n",
    "\n",
    "train_vocab = Vocabulary()\n",
    "train_vocab.fit(itemgetter(*train_idxs)(sentences))\n",
    "\n",
    "train_dataset = MyDataset(itemgetter(*train_idxs)(sentences), vocab=train_vocab)\n",
    "val_dataset = MyDataset(itemgetter(*val_idxs)(sentences), vocab=train_vocab)\n",
    "test_dataset = MyDataset(itemgetter(*test_idxs)(sentences), vocab=train_vocab)\n",
    "\n",
    "print('train len', len(train_dataset))\n",
    "print('val len', len(val_dataset))\n",
    "print('test len', len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.emb = Embedding(vocab_size, emb_dim)\n",
    "        self.gru = GRU(emb_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, lengths, h0):\n",
    "        emb = self.emb(x)\n",
    "#         print(emb.shape)\n",
    "        gru_in = emb\n",
    "#         print(gru_in.shape)\n",
    "        gru_in = pack_padded_sequence(emb, lengths, batch_first=True)\n",
    "        gru_out, gru_hidden = self.gru(gru_in, h0)\n",
    "        gru_out, _ = pad_packed_sequence(gru_out, batch_first=True)\n",
    "#         print(gru_out.shape)\n",
    "        scores = self.fc(gru_out)\n",
    "#         print(scores.shape)\n",
    "        return scores, gru_hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, device=None):\n",
    "        if device:\n",
    "            return torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "        else:\n",
    "            return torch.zeros(self.n_layers, batch_size, self.hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (emb): Embedding(50000, 300)\n",
       "  (gru): GRU(300, 100, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=100, out_features=50000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LanguageModel(len(t.vocab), 300, 100, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8109, grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "cr = torch.nn.CrossEntropyLoss()\n",
    "for (x, y), lengths in loader:\n",
    "    h0 = model.init_hidden(loader.batch_size)\n",
    "    pred, _ = model(x, lengths, h0)\n",
    "#     print(pred.shape, y.shape)\n",
    "    loss = cr(pred.permute(0,2,1), y)\n",
    "#     acc = accuracy(pred, y)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make train, eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, y):\n",
    "\n",
    "    pred_lbl = F.softmax(pred, dim=2).argmax(dim=2)\n",
    "    correct = (pred_lbl == y).float()\n",
    "    acc = torch.mean(correct.sum(dim=1) / correct.shape[1])\n",
    "    return acc\n",
    "\n",
    "def perplexity(pred):\n",
    "    \n",
    "    pred_probs = torch.max(F.softmax(pred, dim=2), dim=2)[0]\n",
    "    perplexity = torch.exp(-torch.mean(torch.log(pred_probs)))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, name):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'model_decription': str(model),\n",
    "        'train_vocab': train_vocab\n",
    "    }, name)\n",
    "\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss, epoch_acc, epoch_perp = 0, 0, 0\n",
    "    for (x, y), lengths in loader:\n",
    "        h0 = model.init_hidden(x.shape[0])\n",
    "        x, y, h0 = x.to(device), y.to(device), h0.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        out, h = model(x, lengths, h0)\n",
    "\n",
    "        loss = criterion(out.permute(0,2,1), y)\n",
    "        acc = accuracy(out, y)\n",
    "        perp = perplexity(out)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_perp += perp.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader), epoch_perp / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss, epoch_acc, epoch_perp = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (x, y), lengths in loader:\n",
    "            h0 = model.init_hidden(x.shape[0])\n",
    "            x, y, h0 = x.to(device), y.to(device), h0.to(device)\n",
    "            \n",
    "            out, _ = model(x, lengths, h0)\n",
    "\n",
    "            loss = criterion(out.permute(0,2,1), y)\n",
    "            acc = accuracy(out, y)\n",
    "            perp = perplexity(out)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_perp += perp.item()\n",
    "            \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader), epoch_perp / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | TRAIN loss: 9.6540, acc: 0.4000, perp: 3878.3890; VAL loss: 9.0664, acc: 0.6880, perp: 1622.7436\n",
      "2 | TRAIN loss: 8.9129, acc: 0.6844, perp: 1346.9217; VAL loss: 8.4764, acc: 0.6939, perp: 946.5124\n",
      "3 | TRAIN loss: 8.2850, acc: 0.6898, perp: 798.6739; VAL loss: 7.9304, acc: 0.6970, perp: 564.0427\n",
      "4 | TRAIN loss: 7.6777, acc: 0.6939, perp: 479.4010; VAL loss: 7.4097, acc: 0.6989, perp: 339.7322\n",
      "5 | TRAIN loss: 7.0844, acc: 0.6973, perp: 289.6778; VAL loss: 6.9062, acc: 0.7000, perp: 206.6346\n",
      "6 | TRAIN loss: 6.5026, acc: 0.7006, perp: 175.4918; VAL loss: 6.4154, acc: 0.7009, perp: 126.7327\n",
      "7 | TRAIN loss: 5.9308, acc: 0.7041, perp: 106.5972; VAL loss: 5.9347, acc: 0.7011, perp: 78.4482\n",
      "8 | TRAIN loss: 5.3692, acc: 0.7079, perp: 64.9932; VAL loss: 5.4621, acc: 0.7012, perp: 48.3533\n",
      "9 | TRAIN loss: 4.8182, acc: 0.7118, perp: 39.7497; VAL loss: 4.9974, acc: 0.7012, perp: 29.9794\n",
      "10 | TRAIN loss: 4.2784, acc: 0.7163, perp: 24.5145; VAL loss: 4.5479, acc: 0.7007, perp: 18.8682\n",
      "11 | TRAIN loss: 3.7597, acc: 0.7213, perp: 15.3199; VAL loss: 4.1201, acc: 0.7002, perp: 12.0394\n",
      "12 | TRAIN loss: 3.2708, acc: 0.7266, perp: 9.8210; VAL loss: 3.7300, acc: 0.6996, perp: 8.0360\n",
      "13 | TRAIN loss: 2.8321, acc: 0.7319, perp: 6.5822; VAL loss: 3.3939, acc: 0.6996, perp: 5.6048\n",
      "14 | TRAIN loss: 2.4633, acc: 0.7372, perp: 4.7064; VAL loss: 3.1295, acc: 0.6991, perp: 4.1646\n",
      "15 | TRAIN loss: 2.1729, acc: 0.7424, perp: 3.6284; VAL loss: 2.9413, acc: 0.6984, perp: 3.3311\n",
      "16 | TRAIN loss: 1.9574, acc: 0.7474, perp: 3.0067; VAL loss: 2.8183, acc: 0.6979, perp: 2.8712\n",
      "17 | TRAIN loss: 1.8012, acc: 0.7521, perp: 2.6343; VAL loss: 2.7436, acc: 0.6968, perp: 2.6536\n",
      "18 | TRAIN loss: 1.6836, acc: 0.7569, perp: 2.3991; VAL loss: 2.6952, acc: 0.6970, perp: 2.4191\n",
      "19 | TRAIN loss: 1.5955, acc: 0.7614, perp: 2.2432; VAL loss: 2.6686, acc: 0.6970, perp: 2.2662\n",
      "20 | TRAIN loss: 1.5290, acc: 0.7651, perp: 2.1336; VAL loss: 2.6631, acc: 0.6941, perp: 2.2925\n",
      "21 | TRAIN loss: 1.4799, acc: 0.7681, perp: 2.0552; VAL loss: 2.6585, acc: 0.6937, perp: 2.2289\n",
      "22 | TRAIN loss: 1.4295, acc: 0.7724, perp: 1.9904; VAL loss: 2.6551, acc: 0.6948, perp: 2.1113\n",
      "23 | TRAIN loss: 1.3880, acc: 0.7762, perp: 1.9389; VAL loss: 2.6626, acc: 0.6939, perp: 2.0777\n",
      "24 | TRAIN loss: 1.3559, acc: 0.7791, perp: 1.8978; VAL loss: 2.6775, acc: 0.6925, perp: 2.0855\n",
      "25 | TRAIN loss: 1.3263, acc: 0.7821, perp: 1.8642; VAL loss: 2.6869, acc: 0.6926, perp: 2.0393\n",
      "26 | TRAIN loss: 1.3015, acc: 0.7847, perp: 1.8353; VAL loss: 2.6963, acc: 0.6930, perp: 1.9848\n",
      "27 | TRAIN loss: 1.2789, acc: 0.7873, perp: 1.8103; VAL loss: 2.7116, acc: 0.6925, perp: 1.9707\n",
      "28 | TRAIN loss: 1.2560, acc: 0.7900, perp: 1.7872; VAL loss: 2.7251, acc: 0.6920, perp: 1.9473\n",
      "29 | TRAIN loss: 1.2361, acc: 0.7924, perp: 1.7675; VAL loss: 2.7391, acc: 0.6924, perp: 1.9087\n",
      "30 | TRAIN loss: 1.2176, acc: 0.7948, perp: 1.7498; VAL loss: 2.7550, acc: 0.6923, perp: 1.8831\n",
      "31 | TRAIN loss: 1.2017, acc: 0.7968, perp: 1.7341; VAL loss: 2.7721, acc: 0.6917, perp: 1.8803\n",
      "32 | TRAIN loss: 1.1868, acc: 0.7987, perp: 1.7201; VAL loss: 2.7891, acc: 0.6910, perp: 1.8777\n",
      "33 | TRAIN loss: 1.1728, acc: 0.8007, perp: 1.7067; VAL loss: 2.8058, acc: 0.6903, perp: 1.8804\n",
      "34 | TRAIN loss: 1.1595, acc: 0.8024, perp: 1.6946; VAL loss: 2.8197, acc: 0.6902, perp: 1.8589\n",
      "35 | TRAIN loss: 1.1487, acc: 0.8039, perp: 1.6843; VAL loss: 2.8351, acc: 0.6902, perp: 1.8557\n",
      "36 | TRAIN loss: 1.1371, acc: 0.8056, perp: 1.6739; VAL loss: 2.8497, acc: 0.6901, perp: 1.8379\n",
      "37 | TRAIN loss: 1.1276, acc: 0.8068, perp: 1.6646; VAL loss: 2.8666, acc: 0.6894, perp: 1.8451\n",
      "38 | TRAIN loss: 1.1188, acc: 0.8080, perp: 1.6568; VAL loss: 2.8781, acc: 0.6895, perp: 1.8197\n",
      "39 | TRAIN loss: 1.1101, acc: 0.8092, perp: 1.6484; VAL loss: 2.8922, acc: 0.6896, perp: 1.8081\n",
      "40 | TRAIN loss: 1.1016, acc: 0.8103, perp: 1.6409; VAL loss: 2.9066, acc: 0.6893, perp: 1.8071\n",
      "41 | TRAIN loss: 1.0923, acc: 0.8117, perp: 1.6339; VAL loss: 2.9223, acc: 0.6892, perp: 1.7945\n",
      "42 | TRAIN loss: 1.0846, acc: 0.8129, perp: 1.6271; VAL loss: 2.9347, acc: 0.6886, perp: 1.7932\n",
      "43 | TRAIN loss: 1.0772, acc: 0.8139, perp: 1.6204; VAL loss: 2.9485, acc: 0.6886, perp: 1.7871\n",
      "44 | TRAIN loss: 1.0688, acc: 0.8151, perp: 1.6139; VAL loss: 2.9612, acc: 0.6887, perp: 1.7783\n",
      "45 | TRAIN loss: 1.0627, acc: 0.8160, perp: 1.6081; VAL loss: 2.9746, acc: 0.6889, perp: 1.7661\n",
      "46 | TRAIN loss: 1.0552, acc: 0.8171, perp: 1.6025; VAL loss: 2.9888, acc: 0.6887, perp: 1.7590\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c89c604b4d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_perp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_perp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-0bdeb6a87c3d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EMB_DIM = 200\n",
    "HIDDEN_DIM = 100\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.5\n",
    "BATCH_S = 80\n",
    "EPOCHS = 150\n",
    "\n",
    "train_loader = DataLoader(train_dataset, BATCH_S, collate_fn=pad_batch, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, BATCH_S, collate_fn=pad_batch, num_workers=4)\n",
    "voc_len = len(train_dataset.vocab)\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "model = LanguageModel(voc_len, EMB_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_loss = np.inf\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_loss, train_acc, train_perp = train(model, train_loader, criterion, optim, device)\n",
    "    val_loss, val_acc, val_perp = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        save_model(model, optim, 'LM.pt')\n",
    "        \n",
    "    print('{} | TRAIN loss: {:.4f}, acc: {:.4f}, perp: {:.4f}; VAL loss: {:.4f}, acc: {:.4f}, perp: {:.4f}'.\n",
    "             format(epoch + 1, train_loss, train_acc, train_perp, val_loss, val_acc, val_perp))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "318.212px",
    "left": "1688.89px",
    "right": "20px",
    "top": "111px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
